{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2eb48b6",
   "metadata": {},
   "source": [
    "# Explore LREC Whisper Armenian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3a3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d8aa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: notebooks\n",
      "Adjusting working directory to project root...\n",
      "New working directory: hy_transcribe\n"
     ]
    }
   ],
   "source": [
    "project_root = 'hy_transcribe' # TODO: Constants\n",
    "working_dir = os.path.basename(os.getcwd())\n",
    "print(f\"Current working directory: {working_dir}\")\n",
    "if 'notebooks' == working_dir: \n",
    "    print(\"Adjusting working directory to project root...\")\n",
    "    os.chdir(\"../\")\n",
    "    working_dir = os.path.basename(os.getcwd())\n",
    "    print(f\"New working directory: {working_dir}\")\n",
    "\n",
    "if working_dir != project_root: \n",
    "    print(f\"WARNING: The working directory could not be set to {project_root}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba69596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lrec_hy_whisper_model.model import LrecHyAsr\n",
    "from src.data_interface.audio_source import AsrAudioSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128eb7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.74it/s]\n",
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n"
     ]
    }
   ],
   "source": [
    "# TODO: Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n",
    "asr = LrecHyAsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f3258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1543490560"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of parameters\n",
    "# You should get about 1.55 billion - this is a finetuned version of the large model (specifically v3)\n",
    "sum(p.numel() for p in asr.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb87a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_source = AsrAudioSource('data/alba_interviews/alba_interview_EA023_M.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd19e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Investigate Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
    "# Let's see if my mac can handle it lol \n",
    "# This audio file is an hour and eight minutes long \n",
    "asr.transcribe_longform_audio(audio_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf16a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hy-transcribe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
